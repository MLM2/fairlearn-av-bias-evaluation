{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fairlearn Bias Evaluation Demo\n\n",
        "This notebook demonstrates **Fairlearn bias evaluation techniques** using the public UCI Adult Income dataset.\n\n",
        "- The techniques shown here are applicable to **AI fairness evaluation** in domains such as AV safety, public policy, and national security contexts.\n",
        "- The UCI Adult Income dataset is used here as a standard public example for demonstrating fairness metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from fairlearn.metrics import MetricFrame, selection_rate, demographic_parity_difference, equalized_odds_difference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load UCI Adult Income dataset\n",
        "adult = fetch_openml(data_id=1590, as_frame=True)\n",
        "df = adult.frame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess data\n",
        "# Use 'sex' as sensitive feature, 'class' as target\n",
        "df = df.dropna()\n",
        "X = df.drop(columns=['class'])\n",
        "y = (df['class'] == '>50K').astype(int)  # Binary target\n",
        "sensitive_feature = X['sex']\n",
        "\n",
        "# Encode categorical features\n",
        "X = X.apply(lambda col: LabelEncoder().fit_transform(col) if col.dtype == 'object' else col)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test, sf_train, sf_test = train_test_split(\n",
        "    X, y, sensitive_feature, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train simple Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {acc:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate fairness metrics\n",
        "metric_frame = MetricFrame(\n",
        "    metrics={\n",
        "        'accuracy': accuracy_score,\n",
        "        'selection_rate': selection_rate\n",
        "    },\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred,\n",
        "    sensitive_features=sf_test\n",
        ")\n",
        "print(metric_frame.by_group)\n",
        "\n",
        "dp_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=sf_test)\n",
        "eo_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=sf_test)\n",
        "\n",
        "print(f'\\nDemographic Parity Difference: {dp_diff:.2f}')\n",
        "print(f'Equalized Odds Difference: {eo_diff:.2f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}